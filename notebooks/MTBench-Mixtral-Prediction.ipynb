{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from typing import Sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import functools\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "import sys\n",
    "if \"notebooks\" in os.path.abspath('.'):\n",
    "    sys.path.append('../')\n",
    "from traces import mtbench_mixtral_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = mtbench_mixtral_utils.load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = list(traces.values())[0]\n",
    "trace.num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trace.experts_per_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_selected_experts(selected_experts: Sequence[int], total_num_experts: int) -> int:\n",
    "    combinations = list(itertools.combinations(range(total_num_experts), 2))\n",
    "    combination = tuple(sorted(selected_experts))\n",
    "    return combinations.index(combination)\n",
    "\n",
    "\n",
    "def create_dataset(traces: Sequence[mtbench_mixtral_utils.QueryTrace], num_past_experts: int, num_experts_to_predict: int, step_size: int, offset: int = 0) -> TensorDataset:\n",
    "    X = [] # Each X is a list of the previously selected experts.\n",
    "    Y = []\n",
    "    for trace in traces:\n",
    "        experts_per_token = trace.experts_per_token()\n",
    "        experts_encoded = np.apply_along_axis(\n",
    "            lambda x: encode_selected_experts(x, trace.num_experts), -1,\n",
    "            experts_per_token)\n",
    "        experts_encoded = experts_encoded.reshape((-1,))\n",
    "        num_combinations = len(list(itertools.combinations(range(trace.num_experts), 2)))\n",
    "        experts_torch = torch.from_numpy(experts_encoded)\n",
    "        experts_one_hot = nn.functional.one_hot(experts_torch, num_combinations).to(torch.float32)\n",
    "        \n",
    "        for i in range(num_past_experts + offset, experts_one_hot.shape[0] - num_experts_to_predict, step_size):\n",
    "            x = experts_one_hot[i - num_past_experts : i]\n",
    "            y = experts_one_hot[i : i + num_experts_to_predict]\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "    X = torch.stack(X)\n",
    "    Y = torch.stack(Y)\n",
    "    return TensorDataset(X.to('mps'), Y.to('mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(traces.values(), 32, 32, 32)\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "training_set, validation_set, test_set = torch.utils.data.random_split(dataset, [0.8, 0.1, 0.1], generator=generator)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "training_loader = DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpPredictor(nn.Module):\n",
    "    def __init__(self, input_shape: tuple[int], output_shape: tuple[int], hidden_dims: Sequence[int]):\n",
    "        super().__init__()\n",
    "        self.output_shape = output_shape\n",
    "        num_inputs = np.prod(input_shape)\n",
    "        num_outputs = np.prod(output_shape)\n",
    "        self.mlp = torchvision.ops.MLP(num_inputs, tuple(hidden_dims) + (num_outputs, ))\n",
    "        print(num_inputs, hidden_dims, num_outputs)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.reshape((batch_size, -1))\n",
    "        y = self.mlp(x)\n",
    "        y = y.reshape((batch_size, *self.output_shape))\n",
    "        z = torch.softmax(y, dim=-1)\n",
    "        return z\n",
    "        \n",
    "\n",
    "# model = torchvision.ops.MLP(28, [32, 28]).to('mps')\n",
    "model = MlpPredictor((32, 28), (32, 28), [32]).to('mps')\n",
    "# model.mlp = model.mlp.to('mps')\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    num_correct_predictions = 0 # torch.tensor(0, dtype=torch.int64).to('mps')\n",
    "    device = torch.device('mps')\n",
    "\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Prediction accuracy\n",
    "        batch_size, pred_layers, _num_combos = labels.shape\n",
    "        pred_x_idx = np.arange(0, batch_size * pred_layers) // batch_size\n",
    "        pred_y_idx = np.repeat(np.arange(0, pred_layers), batch_size)\n",
    "        pred_z_idx = torch.argmax(outputs, -1).reshape((batch_size * pred_layers))\n",
    "        # output_argmax = \n",
    "        # print(argmax)\n",
    "        # print(output_argmax.shape)\n",
    "        predictions = labels[pred_x_idx, pred_y_idx, pred_z_idx]\n",
    "        correct_predictions = predictions > 0.9\n",
    "        num_correct_predictions += correct_predictions.sum()\n",
    "        # print('correct predictions', correct_predictions.sum())\n",
    "        # print('num_correct_predictions', num_correct_predictions)\n",
    "        # print(argmax.shape, argmax.dtype)\n",
    "        # print(labels.shape)\n",
    "        # print((outputs[argmax] == 1).sum())\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "            # batch_size, pred_layers, _ = inputs.shape\n",
    "            past_predictions = 1000 * batch_size * pred_layers\n",
    "            # print(num_correct_predictions)\n",
    "            prediction_accuracy = num_correct_predictions.cpu() /  past_predictions\n",
    "            print('  prediction {} accuracy: {}'.format(i + 1, prediction_accuracy))\n",
    "            tb_writer.add_scalar('Accuracy/train', prediction_accuracy, tb_x)\n",
    "            num_correct_predictions = 0\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/expert_predictor_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.astype(np.uint32)\n",
    "out = np.apply_along_axis(lambda x: encode_selected_experts(x, trace.num_experts), -1, x)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.reshape((-1, )).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_torch = torch.from_numpy(out)\n",
    "out_one_hot = nn.functional.one_hot(out_torch)\n",
    "out_one_hot.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_one_hot[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
