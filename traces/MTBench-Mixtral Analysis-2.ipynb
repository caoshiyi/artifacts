{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e1a7f-05b0-44fb-8225-53efeca6877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from typing import Sequence\n",
    "import functools\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000ce5e-1961-467c-aa70-23ca0f5bad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse log\n",
    "def parse_input_ids(data):\n",
    "    matches = re.findall(r\"input_ids: tensor\\(\\[\\[([\\s\\d,]+)\", data)\n",
    "    return [[int(s.strip()) for s in match.split(',')] for match in matches]\n",
    "\n",
    "def parse_expert_ids(data):\n",
    "    matches = re.findall(r\"Layer (\\d+) topk_ids: tensor\\(\\[([\\[\\]\\d,\\s]+)\\], device\", data)\n",
    "    layer_ids = [int(t[0]) for t in matches]\n",
    "    expert_ids = [[[int(x) for x in s.strip()[1:-1].split(', ')] for s in t[1].split(',\\n')] for t in matches]\n",
    "    return layer_ids, expert_ids\n",
    "\n",
    "def parse_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    input_ids = parse_input_ids(data)\n",
    "    layer_ids, expert_ids = parse_expert_ids(data)\n",
    "    assert len(layer_ids) == len(expert_ids), f\"len(layer_ids)={len(layer_ids)} and len(expert_ids)={len(expert_ids)}\"\n",
    "    assert len(layer_ids) == len(input_ids), f\"len(layer_ids)={len(layer_ids)} and len(input_ids)={len(input_ids)}\"\n",
    "\n",
    "    return layer_ids, input_ids, expert_ids\n",
    "\n",
    "\n",
    "filename = \"MTBench_Mixtral/139916882249008.txt\"\n",
    "layer_ids, input_ids, expert_ids = parse_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dbb942-3091-49b2-b04e-721974622670",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class QueryTrace:\n",
    "    \"\"\"Trace for a query to the LLM.\"\"\"\n",
    "    layer_ids: Sequence[int]\n",
    "    expert_ids: Sequence[Sequence[Sequence[int]]] # layer, token, selected experts\n",
    "    token_expert_ids: Sequence[Sequence[Sequence[int]]] # token, layer, selected experts\n",
    "    input_ids: Sequence[Sequence[int]] # layer, inputs\n",
    "    has_prefix: bool = True\n",
    "\n",
    "    @staticmethod\n",
    "    def from_file(filename):\n",
    "        layer_ids, input_ids, expert_ids = parse_file(filename)\n",
    "        structured_data = {}\n",
    "        # Iterate through each layer and corresponding expert selections\n",
    "        for layer_index, layer in enumerate(layer_ids):\n",
    "            layer_data = structured_data[layer] if layer in structured_data else []\n",
    "            for token_index, token_id in enumerate(input_ids[layer_index]):\n",
    "                # Extract experts for the current token at the current layer\n",
    "                layer_data.append(expert_ids[layer_index][token_index])\n",
    "                # Append structured information for the current token\n",
    "            if layer not in structured_data:\n",
    "                structured_data[layer] = layer_data\n",
    "        token_experts_id = []\n",
    "        for layer in range(32):\n",
    "            token_experts_id.append(structured_data[layer])\n",
    "        return QueryTrace(layer_ids=layer_ids, expert_ids=expert_ids, token_expert_ids=token_experts_id, input_ids=input_ids)\n",
    "\n",
    "    @functools.cached_property\n",
    "    def num_layers(self) -> int:\n",
    "        return len(np.unique(self.layer_ids))\n",
    "\n",
    "    @functools.cached_property\n",
    "    def num_experts(self) -> int:\n",
    "        exp_ids_flat = list(itertools.chain.from_iterable(itertools.chain.from_iterable(self.expert_ids)))\n",
    "        return len(np.unique(exp_ids_flat))\n",
    "\n",
    "    @functools.cached_property\n",
    "    def prompt_token_length(self) -> int:\n",
    "        return len(self.input_ids[0])\n",
    "\n",
    "    @functools.cached_property\n",
    "    def num_generated_tokens(self) -> int:\n",
    "        return len(self.input_ids[1:])\n",
    "\n",
    "    def expert_counts_by_layer(self) -> np.ndarray:\n",
    "        expert_counts_by_layer = np.zeros((self.num_layers, self.num_experts), dtype=np.int32)\n",
    "        for layer_id, exp_ids in zip(self.layer_ids, self.expert_ids):\n",
    "            exp_ids_flat = list(itertools.chain.from_iterable(exp_ids))\n",
    "            counts = np.bincount(exp_ids_flat + list(range(self.num_experts))) - 1 # Ensure all experts are included.\n",
    "            expert_counts_by_layer[layer_id] += np.bincount(exp_ids_flat + list(range(self.num_experts)))\n",
    "\n",
    "        return expert_counts_by_layer\n",
    "\n",
    "    def without_prefix(self):\n",
    "        return QueryTrace(layer_ids=self.layer_ids[self.num_layers:],\n",
    "                          expert_ids=self.expert_ids[self.num_layers:],\n",
    "                          input_ids=self.input_ids[self.num_layers:],\n",
    "                          has_prefix=False)\n",
    "\n",
    "\n",
    "files = !ls MTBench_Mixtral/*\n",
    "\n",
    "traces = {}\n",
    "for filename in files:\n",
    "    try:\n",
    "        trace = QueryTrace.from_file(filename)\n",
    "        traces[filename] = trace\n",
    "    except AssertionError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed6a8b-7235-456f-9dcd-79de73cbe284",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_counts_by_layer = sum(trace.expert_counts_by_layer() for trace in traces.values())\n",
    "expert_freq_by_layer = expert_counts_by_layer / expert_counts_by_layer.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "ax = sns.heatmap(expert_freq_by_layer, linewidths=.5, cmap='rocket_r',\n",
    "                 cbar_kws={'label': 'Frequency'})\n",
    "ax.invert_yaxis()\n",
    "ax.set_yticks(0.5 + np.arange(0, 32, 4), np.arange(0, 32, 4))\n",
    "plt.xlabel(\"Expert ID\")\n",
    "plt.ylabel(\"Layer\")\n",
    "plt.title(\"Mixtral on MTBench\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd201d98-9050-4bc3-8366-0ebf0f49b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "sns.barplot(x=np.arange(0, 32), y=expert_freq_by_layer.std(axis=1))\n",
    "plt.xlabel(\"Layer Number\")\n",
    "plt.ylabel(\"Standard Deviation\\nof Expert Frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2441abf6-55ac-48b0-90d5-fecd45796854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_next_expert_given_previous_experts(traces: dict, k=2):\n",
    "    # (layer, previous_expert_0, previous_expert_1, next_expert)\n",
    "    trace = next(iter(traces.values()))\n",
    "    combinations = list(itertools.combinations(list(range(trace.num_experts)), k))\n",
    "    print(combinations)\n",
    "    num_combinations = len(combinations)\n",
    "    combination_to_idx = {c: i for i, c in enumerate(combinations)}\n",
    "    counts = np.zeros((trace.num_layers, num_combinations, trace.num_experts), dtype=np.uint32)\n",
    "    for trace_name, trace in traces.items():\n",
    "        # trace = trace.without_prefix()\n",
    "        for layer_id, cur_experts, next_experts in zip(trace.layer_ids, trace.expert_ids, trace.expert_ids[1:]):\n",
    "            # assert len(cur_experts) == 1, f'{len(cur_experts)} should be 1 for {trace_name}'\n",
    "            for per_token_cur_experts, per_token_next_experts in zip(cur_experts, next_experts):\n",
    "                combination = tuple(sorted(per_token_cur_experts))\n",
    "                combination_idx = combination_to_idx[combination]\n",
    "                counts[layer_id, combination_idx, per_token_next_experts] += 1\n",
    "\n",
    "    sum = counts.sum(axis=-1)\n",
    "    divisor = np.maximum(sum, np.ones_like(sum)) # Avoid dividing by 0\n",
    "    probabilities = counts / sum[:, :, np.newaxis]\n",
    "    return probabilities, combination_to_idx\n",
    "\n",
    "probabilities, experts_to_idx = p_next_expert_given_previous_experts(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92146f8c-cadc-42e0-b507-2ed3595197a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probabilities(layer_id, probabilities, experts_to_idx):\n",
    "    ax = sns.heatmap(probabilities[layer_id], linewidths=.5, cmap='rocket_r',\n",
    "                     cbar_kws={'label': 'Probability'}, vmin=0, vmax=0.5)\n",
    "    ax.invert_yaxis()\n",
    "    plt.xlabel(\"Next Experts\")\n",
    "    plt.ylabel(\"Current Experts\")\n",
    "    plt.title(f\"Layer {layer_id}\")\n",
    "    \n",
    "    yticks = np.arange(0, len(experts_to_idx), 1)\n",
    "    idx_to_experts = {i: e for e, i in experts_to_idx.items()}\n",
    "    yticklabels = [idx_to_experts[i] for i in yticks]\n",
    "    ax.set_yticks(yticks + 0.5, yticklabels)\n",
    "    # plt.xticks(fontsize=5)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "for i in range(32):\n",
    "    plot_probabilities(i, probabilities, experts_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0731c02-e1c7-484b-a268-5f2b550c6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_next_experts_given_previous_experts(traces: dict, k=2):\n",
    "    # (layer, previous_expert_0, previous_expert_1, next_expert)\n",
    "    trace = next(iter(traces.values()))\n",
    "    combinations = list(itertools.combinations(list(range(trace.num_experts)), k))\n",
    "    num_combinations = len(combinations)\n",
    "    combination_to_idx = {c: i for i, c in enumerate(combinations)}\n",
    "    counts = np.zeros((trace.num_layers, num_combinations, num_combinations), dtype=np.uint32)\n",
    "    for trace_name, trace in traces.items():\n",
    "        # trace = trace.without_prefix()\n",
    "        for layer_id, cur_experts, next_experts in zip(trace.layer_ids, trace.expert_ids, trace.expert_ids[1:]):\n",
    "            # assert len(cur_experts) == 1, f'{len(cur_experts)} should be 1 for {trace_name}'\n",
    "            for per_token_cur_experts, per_token_next_experts in zip(cur_experts, next_experts):\n",
    "                print(per_token_next_experts)\n",
    "                combination = tuple(sorted(per_token_cur_experts))\n",
    "                combination_idx = combination_to_idx[combination]\n",
    "                next_comb = tuple(sorted(per_token_next_experts))\n",
    "                next_comb_idx = combination_to_idx[next_comb]\n",
    "                counts[layer_id, combination_idx, next_comb_idx] += 1\n",
    "\n",
    "    sum = counts.sum(axis=-1)\n",
    "    divisor = np.maximum(sum, np.ones_like(sum)) # Avoid dividing by 0\n",
    "    probabilities = counts / sum[:, :, np.newaxis]\n",
    "    return probabilities, combination_to_idx\n",
    "\n",
    "probabilities, experts_to_idx = p_next_experts_given_previous_experts(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0838e2ba-cdf9-48b3-a2e0-b5b5c111dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probabilities(layer_id, probabilities, experts_to_idx):\n",
    "    ax = sns.heatmap(probabilities[layer_id], linewidths=.5, cmap='rocket_r',\n",
    "                     cbar_kws={'label': 'Probability'}, vmin=0, vmax=0.5)\n",
    "    ax.invert_yaxis()\n",
    "    plt.xlabel(\"Next Experts\")\n",
    "    plt.ylabel(\"Current Experts\")\n",
    "    plt.title(f\"Layer {layer_id}\")\n",
    "    \n",
    "    yticks = np.arange(0, len(experts_to_idx), 1)\n",
    "    idx_to_experts = {i: e for e, i in experts_to_idx.items()}\n",
    "    yticklabels = [idx_to_experts[i] for i in yticks]\n",
    "    ax.set_yticks(yticks + 0.5, yticklabels)\n",
    "\n",
    "    ax.set_xticks(yticks + 0.5, yticklabels)\n",
    "    plt.xticks(rotation=90)\n",
    "    # plt.xticks(fontsize=5)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.savefig(f\"layer{layer_id}_layer_layer.png\", dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "for i in range(32):\n",
    "    plot_probabilities(i, probabilities, experts_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a3dc4-6dce-4145-8174-4aefe0478e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_next_token_experts_given_previous_token_experts(traces: dict, k=2):\n",
    "    # (layer, previous_expert_0, previous_expert_1, next_expert)\n",
    "    trace = next(iter(traces.values()))\n",
    "    combinations = list(itertools.combinations(list(range(trace.num_experts)), k))\n",
    "    num_combinations = len(combinations)\n",
    "    combination_to_idx = {c: i for i, c in enumerate(combinations)}\n",
    "    counts = np.zeros((trace.num_layers, num_combinations, num_combinations), dtype=np.uint32)\n",
    "    for trace_name, trace in traces.items():\n",
    "        for layer_id in list(range(trace.num_layers)):\n",
    "            for per_token_cur_experts, per_token_next_experts in zip(trace.token_expert_ids[layer_id], trace.token_expert_ids[layer_id][1:]):\n",
    "                print(per_token_next_experts)\n",
    "                combination = tuple(sorted(per_token_cur_experts))\n",
    "                combination_idx = combination_to_idx[combination]\n",
    "                next_comb = tuple(sorted(per_token_next_experts))\n",
    "                next_comb_idx = combination_to_idx[next_comb]\n",
    "                counts[layer_id, combination_idx, next_comb_idx] += 1\n",
    "\n",
    "    sum = counts.sum(axis=-1)\n",
    "    divisor = np.maximum(sum, np.ones_like(sum)) # Avoid dividing by 0\n",
    "    probabilities = counts / sum[:, :, np.newaxis]\n",
    "    return probabilities, combination_to_idx\n",
    "\n",
    "probabilities, experts_to_idx = p_next_token_experts_given_previous_token_experts(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a0d77-6a51-4014-ad02-2a5299323e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probabilities(layer_id, probabilities, experts_to_idx):\n",
    "    ax = sns.heatmap(probabilities[layer_id], linewidths=.5, cmap='rocket_r',\n",
    "                     cbar_kws={'label': 'Probability'}, vmin=0, vmax=0.5)\n",
    "    ax.invert_yaxis()\n",
    "    plt.xlabel(\"Next Experts\")\n",
    "    plt.ylabel(\"Current Experts\")\n",
    "    plt.title(f\"Layer {layer_id}\")\n",
    "    \n",
    "    yticks = np.arange(0, len(experts_to_idx), 1)\n",
    "    idx_to_experts = {i: e for e, i in experts_to_idx.items()}\n",
    "    yticklabels = [idx_to_experts[i] for i in yticks]\n",
    "    ax.set_yticks(yticks + 0.5, yticklabels)\n",
    "\n",
    "    ax.set_xticks(yticks + 0.5, yticklabels)\n",
    "    plt.xticks(rotation=90)\n",
    "    # plt.xticks(fontsize=5)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.savefig(f\"layer{layer_id}_token_token.png\", dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "for i in range(32):\n",
    "    plot_probabilities(i, probabilities, experts_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d46b2a-125e-41c1-b0b5-ba38d3e2cd96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
